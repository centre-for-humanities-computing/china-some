{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' VMP 2022-03-05: \n",
    "based on Analysis_RASMUS.ipynb\n",
    "some changes to make it work. \n",
    "double-check with Nielbo. \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cnsome/topic-model/helper_functions.py:48: MatplotlibDeprecationWarning: \n",
      "The createFontList function was deprecated in Matplotlib 3.2 and will be removed two minor releases later. Use FontManager.addfont instead.\n",
      "  font_list = font_manager.createFontList(font_files)\n",
      "/home/cnsome/china_twitter/lib/python3.6/site-packages/ipykernel_launcher.py:30: MatplotlibDeprecationWarning: \n",
      "The createFontList function was deprecated in Matplotlib 3.2 and will be removed two minor releases later. Use FontManager.addfont instead.\n"
     ]
    }
   ],
   "source": [
    "#### Imports\n",
    "import pandas as pd \n",
    "import pickle as pkl \n",
    "import altair as alt\n",
    "import numpy as np \n",
    "import os \n",
    "\n",
    "# setting up matplotlib settings\n",
    "# Source: https://towardsdatascience.com/making-matplotlib-beautiful-by-default-d0d41e3534fd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import matplotlib.font_manager as font_manager\n",
    "\n",
    "#%matplotlib inline\n",
    "from pandas.plotting import scatter_matrix\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "import re\n",
    "import pyLDAvis\n",
    "\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from helper_functions import *\n",
    "\n",
    "\n",
    "# font\n",
    "font_dirs = ['/Library/Fonts', ]\n",
    "font_files = font_manager.findSystemFonts(fontpaths=font_dirs)\n",
    "font_list = font_manager.createFontList(font_files)\n",
    "font_manager.fontManager.ttflist.extend(font_list)\n",
    "\n",
    "plt.rcParams['font.family'] = 'DIN Condensed Bold'\n",
    "\n",
    "# set matplotlib aesthetics\n",
    "CB91_Blue = '#2CBDFE'\n",
    "CB91_Green = '#47DBCD'\n",
    "CB91_Pink = '#F3A0F2'\n",
    "CB91_Purple = '#9D2EC5'\n",
    "CB91_Violet = '#661D98'\n",
    "CB91_Amber = '#F5B14C'\n",
    "\n",
    "color_list = [CB91_Blue, CB91_Pink, CB91_Green, CB91_Amber,\n",
    "              CB91_Purple, CB91_Violet]\n",
    "\n",
    "plt.rcParams['axes.prop_cycle'] = plt.cycler(color=color_list)\n",
    "\n",
    "sns.set(rc={\n",
    "            'axes.axisbelow': False,\n",
    "            'axes.edgecolor': 'lightgrey',\n",
    "            'axes.facecolor': 'None',\n",
    "            'axes.grid': False,\n",
    "            'axes.labelcolor': 'dimgrey',\n",
    "            'axes.spines.right': False,\n",
    "            'axes.spines.top': False,\n",
    "            'figure.facecolor': 'white',\n",
    "            'lines.solid_capstyle': 'round',\n",
    "            'patch.edgecolor': 'w',\n",
    "            'patch.force_edgecolor': True,\n",
    "            'text.color': 'dimgrey',\n",
    "            'xtick.bottom': False,\n",
    "            'xtick.color': 'dimgrey',\n",
    "            'xtick.direction': 'out',\n",
    "            'xtick.top': False,\n",
    "            'ytick.color': 'dimgrey',\n",
    "            'ytick.direction': 'out',\n",
    "            'ytick.left': False,\n",
    "            'ytick.right': False,\n",
    "            'savefig.dpi': 800})\n",
    "\n",
    "#plt.rcParams[\"savefig.dpi\"] = 'figure'\n",
    "sns.set_context(\"notebook\", rc={\"font.size\":12,\n",
    "                                \"axes.titlesize\":16,\n",
    "                                \"axes.labelsize\":16})\n",
    "\n",
    "\n",
    "#alt.data_transformers.disable_max_rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data (from \"helper_functions.py\") points to the updated data (so fine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, diplomats, media = prep_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cnsome/china_twitter/lib/python3.6/site-packages/scipy/sparse/sparsetools.py:21: DeprecationWarning: `scipy.sparse.sparsetools` is deprecated!\n",
      "scipy.sparse.sparsetools is a private module for scipy.sparse, and should not be used.\n",
      "  _deprecated()\n",
      "/home/cnsome/china_twitter/lib/python3.6/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# load models (from \"helper_functions.py\") points to the updated models (so fine)\n",
    "# some warnings here\n",
    "media_dict, diplo_dict = load_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for the below I have just used the code in Analysis_RASMUS.ipynb\n",
    "# not sure whether diplo_dict() should be filtered for retweets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25830\n",
      "8\n",
      "(25830, 8)\n"
     ]
    }
   ],
   "source": [
    "### trouble-shoot the problem (IndexError: --> theta_transform[i,j] = var)\n",
    "print(len(theta)) # 25.830 elements\n",
    "print(len(theta[0])) # length 8 for the first element -- issue is that some elements are longer. \n",
    "print(theta_transform.shape) # and this is exactly what we specify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "### find \"longest\" list in theta (topics)\n",
    "# this is the issue -- the longest list has 30 elements \n",
    "ntopics_lst = []\n",
    "for (i, doc) in enumerate(theta):\n",
    "    ntopics_lst.append(len(doc))\n",
    "max_topics = max(ntopics_lst)\n",
    "print(max_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] predicting Î¸...\n",
      "*************************\n",
      "[INFO] processed 5000/25830\n",
      "[INFO] processed 10000/25830\n",
      "[INFO] processed 15000/25830\n",
      "[INFO] processed 20000/25830\n",
      "[INFO] processed 25000/25830\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'diplo_without' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-9eef5ae5f8e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta_transform\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'var {i}'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheta_transform\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mdfout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdiplo_without\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'diplomats_noretweet_theta_df.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mdfout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'diplo_without' is not defined"
     ]
    }
   ],
   "source": [
    "# Task 1: Diplomat document representation and metadata\n",
    "## add $\\theta$ to to diplomats\n",
    "\n",
    "## comment0: diplo_without, model is trained without retweet to avoid redundancy\n",
    "## comment1: corpus is filtered for extremes with Gensim \n",
    "## comment2 (VMP 2022-03-05): using max_topics, rather than len(theta[0]). \n",
    "\n",
    "# predict theta_i on document in corpus \n",
    "print(f'\\n[INFO] predicting \\u03B8...\\n{\"*\"*25}')\n",
    "verbose = 5000\n",
    "theta = list()\n",
    "for i, doc in enumerate(diplo_dict['corpus']):\n",
    "    vector = diplo_dict['model'][doc]\n",
    "    theta.append(vector[0])\n",
    "    if verbose > 0 and i > 0 and (i + 1) % verbose == 0:\n",
    "        print(f'[INFO] processed {i + 1}/{len(diplo_dict[\"corpus\"])}')\n",
    "# dimension consistent theta array\n",
    "(m, k) = (len(theta), max_topics) #kappa VMP2022-03-05: (previously: (len(theta), len(theta[0])))\n",
    "theta_transform = np.zeros((m, k))\n",
    "for (i, doc) in enumerate(theta):\n",
    "    theta_i = np.zeros((1,30)) # VMP: where is this used?\n",
    "    for j, var in doc:\n",
    "        theta_transform[i,j] = var\n",
    "# write to csv\n",
    "df = pd.DataFrame()\n",
    "for i in range(len(theta_transform[0,:])):\n",
    "    df[f'var {i}'] = theta_transform[:,i]\n",
    "dfout = pd.concat([diplo_without, df], axis=1)\n",
    "fname = os.path.join('data', 'diplomats_noretweet_theta_df.csv')\n",
    "dfout.to_csv(fname, index=False)\n",
    "print(f'{\"*\"*25}\\n[INFO] data exported to {fname}')\n",
    "fname_maxqda = fname.split('.')[0] + '.xlsx'\n",
    "dfout['created_at'] = dfout['created_at'].astype(str)\n",
    "dfout.to_excel(fname_maxqda, index=False)\n",
    "print(f'[INFO] data exported to {fname_maxqda}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "china_twitter",
   "language": "python",
   "name": "china_twitter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
